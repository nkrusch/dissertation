%! suppress = LabelConvention
%! suppress = TooLargeSection
%! suppress = MissingLabel
%! suppress = NonBreakingSpace
\section{Seeking Strong Software Quality Guarantees}
\label{sec:aicc-intro}

A gold standard in formal verification is showing that a program is \emph{totally correct}.
Total correctness requires proving two conditions about the program~\cite{leino2023}.
The first is showing that the program meets its specification.
A \emph{specification} is a mathematically-precise description of program's expected behavior.
Typically, specifications describe \emph{functional} behavior -- a correct program must compute the expected output for all inputs.
The second condition is showing that the program terminates.
Termination guarantees that we will observe the program's output \emph{eventually}.
Thus, proving total correctness gives strong assurance that the program behaves expectedly at \emph{runtime}, when the program is executed.

An additional consideration in formal verification concerns \emph{non-functional} properties.
Non-functional properties characterize the program's quality features, like execution latency, power consumption, and information flow security~\cite{terbeek2018}.
Pure functional correctness is \emph{practically unsatisfactory} if a program requires exorbitant time to compute its result, aggressively drains a device battery, or reveals secret information~\cite{heraud2011,aubert20222}.
Thus, engineering high-quality programs requires we also formally verify non-functional behavior.
Unfortunately, the task is non-trivial, and generally undecidable~\cite{rice1953}.
Among active research topics are developing specification formalisms and reasoning methods that enable verifying programs against non-functional properties~\cite{etaps2025}.

The field of \emph{Implicit Computational Complexity (ICC)}~\cite{dallago2011} offers a conceivable pathway toward formal verification of certain non-functional properties.
Broadly, {complexity theory} reasons about resource requirements of computations.
Those requirements are organized in a hierarchy of \emph{complexity classes}.
The classes describe resource requirements \wrt a machine model.
The classes correspond roughly to real-world programs' running time, memory consumption, \etc
Implicit computational complexity complements the classical theory by aiming to discover \emph{machine}\hyp{}\emph{independent} characterizations of complexity classes.
ICC systems are designed by introducing a \emph{restriction}, at the level of a programming language, that guarantees a complexity property.
Every program satisfying the restriction is known to belong to a particular complexity class~\cite{pchoux2020}%
\IfFileExists{icc}{---\cf~\autoref{fig:icc_systems}.\input{icc}}{.}

Exchanging machine models for syntactic criteria is powerful in several ways.
For example, it facilitates formal verification of programs.
ICC enables defining \emph{syntactical} specifications of resource consumption, and developing fully \emph{automatable} analyses to verify whether a program satisfies such specification~\cite{heraud2011}.
ICC systems have been designed for numerous combinations of programming languages (imperative,  lambda-calculus, function algebras, quantum, term rewrite systems, \(\pi\)-calculus, \ldots), restriction-techniques (linear logic, data-flow analysis, type systems, category theory, \ldots), and complexity classes (\textsc{p}, \textsc{pspace}, \textsc{l}, \textsc{pp}, \ldots)~\cite{moyen2017,pchoux2020}.

\section{Addressed Problem and Goals}
\label{sec:aicc-goals}

Besides uses in formal verification, there are many good motivations for implicit reasoning about complexity.
ICC allows guaranteeing program properties \emph{by construction}, before any program exists.
ICC drives better understanding of complexity classes and yields more natural definitions and proofs of central results than classical complexity theory~\cite{kristiansen2017}.
Multiple ICC systems, \eg~\cite{jones2009,marion2011}, are rich enough to express {natural} algorithms.
Since the reasoning techniques differ from alternative analyses, the results ICC systems produce are often orthogonal to the alternatives~\cite{aubert20222}.
Finally, many ICC systems---\eg~\cite{jones2009,marion2011,hainry2023,atkey2024}---are \emph{compositional}, a kind of modular reasoning approach.
Compositionality is critical for scalability~\cite{carbonneaux2015} and useful for proving soundness~\cite{keidel2021}, \ie that the analysis itself is correct.
However, compositionality is missed by many prominent program analysis techniques~\cite{carbonneaux2015,schiebel2024}.

Despite this rich inventory of compelling features, implicit computational complexity has remained largely a theoretical novelty, with a few exceptions~\cite{avanzini2017,avanzini2008,moyen20172,hainry2021,hoffmann2012,feree2018}.
A theory in absence of applications means the power, limitations, and utilities of the theory are difficult to recognize%%\footnote{Reviewer \#2 might even call such theory \enquote{useless}.}
.
In our view~\cite[pg. xxxv]{bishop2003}~\cite[p. 75]{moyen2017}, theory and application are \emph{symbiotic}.
Investigations of both are needed for scientific advancement.

An embedded manifesto of the dissertation is that \emph{applications are necessary} to push forward our collective understanding of implicit computational complexity.
Potentially great power is locked in the theoretical systems, but it remains an open problem to release that power.
Within the ICC community, more investigations are needed to explore the capabilities of the existing systems.
Externally, the ICC-style analyses should be exposed to broader research communities.
These steps would motivate enhancements in ICC systems and facilitate discovery of their new applications.

The work in the dissertation is only a small step toward these ambitious long-term goals.
The realistic expectations of the dissertation are about technical and social advancement.
Overall, there are four high-level goals.
\begin{enumerate}
\item Extend {applied} capabilities of ICC in automatic program analysis and verification.
\item Take ICC-bases analyses a few steps closer to becoming a standard in real world development workflows.
\item Initiate discourse on relevance of applications within the ICC community.
\item Expose ICC-based analyses to broader research communities.
\end{enumerate}
A guiding intuition behind these goals is that, {if applied}, implicit computational complexity could provide us new practical program analyses.
The use cases include formal verification of \emph{many} non-functional properties.

\section{Research Questions and Approaches}
\label{aicc-approaches}

To guide the dissertation investigation, we define the following \emph{main hypothesis}.
\begin{quote}
\noindent Implicit computational complexity offers applied utilities when lifted outside the theoretical domain.
\end{quote}
Since the hypothesis is broad, the research projects that challenge it must be more refined.
We focus on two paths.
The first applies ICC in automatic analysis of \emph{resource consumption}.
This application is natural because it parallels the theoretical use of ICC.
The second path takes the investigation to a more unconventional direction.
It asks whether we can adjust ICC systems to track \emph{other program properties}, beyond resource consumption.
To summarize, we investigate whether we can
\begin{enumerate*}[label=(\roman*)]
\item use the systems in their designed ways, and
\item discover their unexpected applications.
\end{enumerate*}

\subsection{Automatic Resource Analysis}
\label{subsec:aicc-automatic-resource-analysis}

This series of work centers on an ICC system called the \emph{flow calculus of mwp-bounds}~\cite{jones2009}.
The flow calculus is a canonical example of a theoretical ICC system.
It analyzes imperative programs to determine if it is possible to bound the growth of variable values by polynomials.
The choice to focus on this particular system is based on intuition.
As a syntactical and compositional data-flow analysis, it \emph{seems like} a good candidate for automatic resource analysis.
Several research questions arise from the flow calculus.

\begin{enumerate}[label={(RQ\arabic*)}]
\item Can we develop an \emph{automatic} program analysis based on the theory?
\item Given its paper proofs, is the theory correct?
      Can we prove formally the soundness of the flow calculus?
\item Assuming the theory can be automated, what are the use cases of the analysis?
\end{enumerate}
These questions are still conventional because they focus on resource analysis.
In other words, given a complexity-theoretic technique, we should reasonably expect that it can be applied in the designed way.
If successful, the investigation should minimally produce two research artifacts---a program analyzers and mechanized proof---corresponding to RQ1 and RQ2.
Additionally, it should produce new insights of the flow calculus and its possible applications.
Since ICC is not the only technique for analyzing resource consumption,
having an automatic analysis would enable comparing it with the alternative approaches.

\subsection{Analyzing Extended Program Properties}
\label{subsec:extended-props}

The second series of work applies implicit computational complexity to track \emph{other} non-functional program properties.
The idea is to pick an ICC system, then adjust it to capture a different  property.
The motivation is multifaceted.
On the technical side, it requires deep inspection of the ICC system and challenging its flexibility.
Conceptually, it pushes to think about ICC outside the usual frame of complexity theory.
Lastly, investigations in this direction are important to expose ICC to wider research communities.

In this series of work, the starting point is an ICC system based on quasi-invariants (QI), as formulated in~\cite{moyen20172}.
Similar to the flow calculus, the QI framework is a data-flow analysis of imperative programs.
However, the QI framework supports a richer input language and is founded on an adjustable mathematical framework.
In the prior formulation~\cite{moyen20172}, it was used to obtain a compile-time program optimization.
The optimization lifts nested loops outside their containing loop, such that post-transformation, the program complexity is reduced.
We ask the following questions about the extended uses of the QI framework.
\begin{enumerate}[label={(RQ\arabic*)}]
\setcounter{enumi}{3}
\item How to develop a program transformation to increase parallelization potential?
\item How to use it to analyze security properties, specifically non-interference?
\end{enumerate}
Research questions 4 and 5 are posed here with an air of obviousness.
However, arriving to those questions was not obvious.
A substantial challenge in the research plan involves identifying suitable research domains---like parallel programming or language-based security---where ICC techniques could offer meaningful benefit.

Another consideration is that when we adjust an ICC system, we may lose the original guarantee about resource consumption.
But, in turn, we gain an alternative guarantee.
Whether this trade is beneficial depends on the application.
Therefore, this series of investigation is not just about tracking properties.
It is also about studying the mechanics of ICC systems and uncovering how exactly they provide behavioral guarantees.

Finally, this investigation direction embeds a bonus-challenge.
Simply showing that an ICC-based technique can solve a problem in another application domain is not enough.
It is necessary to show that the solution is \emph{independently} relevant in the target domain, regardless of the origins of the solution.
This criterion is strongly enforced by the scientific peer review process.

\section{Methodology and Research Deliverables}
\label{aicc-methods}

Following the approaches of~\autoref{aicc-approaches}, we conducted a series of investigations.
These resulted in several publications~\cite{aubert20222,aubert20232,aubert2023b},
workshop presentations~\cite{aubert20231,aubert202217,splash22}, and ongoing work.
\IfFileExists{papers}{\input{papers}The dependence associations of the written works are illustrated in~\autoref{fig:papers}.}{}
%The presentation venues include programming languages, verification, formal methods, and security communities.
We can summarize the main contributions as follows.

For RQ1, we enhanced the theory to develop an automatic resource analysis in~\cite{aubert20222,aubert2023b,rusch2025}.
Due to inherent nondeterminism, developing an efficient and useful practical analysis was surprisingly difficult, but ultimately achievable.
The enhanced analysis is more expressive,
\ie it covers a larger class of programs than the original theory~\cite{rusch2025}.
The flow calculus is implemented as an open source static analyzer, pymwp%
\footnote{Pronounced \emph{pa\textsc{i} em double-you p\={e}.}}%
\footnote{https://statycc.github.io/pymwp/}{ }for analyzing C programs~\cite{aubert2023b}.
Based on this work, we discovered that the analysis can support
inference of formal specification conditions~\cite{rusch2025}, corresponding to RQ3.
Proving the soundness of the flow calculus, RQ2, is still ongoing work~\cite{aubert20232}.
However, given the other developments, a formalization effort is now even more strongly motivated and justified.

Along the second direction, for RQ4, we applied the QI framework to develop a program optimization for loop parallelization~\cite{aubert20232}.
This application is useful, because it can be applied to loops whose iteration count is unknown.
Parallelizing such loops is outside the capabilities of the prior techniques.
An ongoing investigation, for RQ5, applies the QI framework to tracking programs \emph{non\hyp{}interference}, a kind of confidentiality property.
Non-interference ensures a program does not reveal secrets;
and if it does, we can identify where the violations occur.
Our working intuition is that, since the analysis can be adjusted to different programming languages, the analysis enables evaluating \emph{preservation} of non-interference property at different compilation stages, while a program is transformed from source code to an executable.
This is different from many existing techniques that analyze programs only at one level of representation.

\section{Research Findings and Conclusions}
\label{aicc-discussion}

%! suppress = IncorrectSectionNesting
\paragraph*{On automatic resource analysis.}
We can now confirm that it is possible to obtain automatic program analysis from the flow calculus of mwp-bounds, but only after substantial adjustments.
An efficient program analysis required inventing ways to manage costly sub-computations and solving additional problems that arose in the process.
At conclusion, the enhanced technique is not just automatable, but can analyze more programs than the original theory.
We can now confirm the analysis results are complementary to alternative state-of-the-art techniques~\cite[p. 5]{aubert2023b}.
Thus, it enables us to analyze different questions about resource consumption.
The implemented flow calculus can also be used in specification inference.
There are potentially many more applications remaining to be discovered.

\paragraph*{On analysis of extended program properties.}
The QI framework provides a case example showing that ICC systems can be flexible enough to track other program properties.
While adjusting the system, we made a surprising discovery in that changing the property of interest simplified the mathematical analysis.
For example, to track a complexity property, we must compute fixed points and preserve the program command order.
In the adjusted analyses, it was possible to relax these conditions.
More generally, that the QI framework can be used to track various properties is reminiscent of the Dependency Core Calculus (DCC)~\cite{abadi1999b}.
In DCC, different program properties are modeled as \emph{instances} of a central notion of \emph{dependency}.
This mirrors our observations about the QI framework.
This suggests that the QI framework encapsulates even wider utility than uncovered during this dissertation work.

\paragraph*{On broader dissertation goals.}
Zooming out of the specific projects, we can reflect on the main hypothesis and the research goals.
We have successfully gathered evidence of the application potential of ICC.
The evidence supports the main hypothesis, but is still too limited to draw generalizing conclusions.
However, our experiences of developing the ICC systems strongly reinforced the symbiotic view of theory and application.
In the process, we faced scientific and engineering challenges, and identified compelling motivations to justify the investigations.
At conclusion, we have strengthened the theories and clarified their practical relevance.

In~\autoref{sec:aicc-goals}, we crafted four goals to define the dissertation expectations.
The first was about extending the applied capabilities of ICC, which was met successfully.
The second was about introducing ICC in development workflows.
Although we have developed a static analyzer, it is a step in \enquote{isolation.}
Integrating ICC analyses into other development tools (compilers, verifiers, \etc) remains as an outstanding task.
Such integration is important to promote relevance and continue development of ICC {applications}.
Our work in using the flow calculus to infer specification conditions~\cite{rusch2025} is a first step in that direction.
The last two goals were social and about disseminating ideas across research communities.
Within the ICC community, our efforts included seminar talks.
Although this record is below ideal, our ideas will remain discoverable to others in written form, asynchronously and in perpetuity, like~\cite{moyen2017}.
In regard to other communities, we were successful at presenting the work at verification, programming languages, and security venues.
Thus, the fourth goal was satisfactorily met.

\paragraph*{Final thoughts \& future perspectives.}
The ICC approach of guaranteeing program properties demonstrates great applied potential;
for example, toward formal verification of non-functional properties.
One investigative direction that deserves more attention is applying ICC to guarantee properties by construction.
This would provide guarantees before any program exists and eliminates the need for \emph{aposteriori} analysis.
Although the dissertation did not extend that far, exploring this direction is an intriguing future goal.
Whether it is attainable depends crucially on a viewpoint shift.
We should regard ICC in the broader context it offers and continue exploration of its applied potential.
