
\subsection*{Abstract}

This work drafts a strategy that leverages the field of Implicit Computational
Complexity to certify resource usage in imperative programs. This original
approach sidesteps some of the most common--and difficult--obstacles
\enquote{traditional} complexity theory face when implemented in
Coq\index{Coq|seealso{Rocq}}.

\subsection{Motivation}
\label{subsec:coqpl-motivation}

The ability to statically infer resource bounds of programs offers numerous
benefits, \eg to insure safe memory usage. Even more preferable if those
guarantees are established with the rigor of formal verification, because that
increases confidence in the obtained analysis result and enables integration of
complexity analyses into larger formal developments.

Unfortunately, computational complexity is notoriously difficult to represent
formally for several reasons. In general, deriving a complexity bound for an
arbitrary program is an undecidable\index{undecidability} problem. In the area
of \ndx{complexity theory}, \textcquote[p.~114]{forster2020}{formalisations of
even basic complexity-theoretic results are not available}, hindering
certification attempts.

For practical complexity analyses\index{complexity analysis}, many existing
techniques present methodological challenges if they require \eg program
termination or inlining functions~\cite{carbonneaux2015}. Therefore, a realistic
pathway toward formal certification of a program's \ndx{resource usage} is
narrow. A few encouraging early results exist, and we discuss some of those in
\autoref{subsec:coqpl-related}. In this proposal we will sketch how a different
approach, founded on Implicit Computational Complexity, could sidestep some of
the usual difficulties in implementing and verifying complexity analyses in
\ndx{Coq}.

The field of Implicit Computational Complexity (ICC)~\cite{dallago2011} drives
better understanding of \ndx{complexity classes}, but it also guides the
development of resources-aware languages and static source code analyzers. The
core idea is to bound resources \emph{while the program is being written (or
type checked)} instead of measuring its resource usage afterwards on an abstract
model of computation\index{machine model}. This can be done through \eg bounded
recursion or using typing mechanisms. The goal is to find a syntactical
restriction or a type system such that a program can be written or typed only if
it belongs to a particular complexity class. ICC-based systems are often
compositional\index{compositionality}, and they offer more natural tools to
write programs than theoretical models of computation used in \ndx{complexity
theory}. We speculate these combined properties could make ICC-approaches a
conceivable pathway toward certified complexity and sketch a more detailed plan
below.

\subsection{Preliminary Action Plan}
\label{subsec:coqpl-preliminary-action-plan}

We plan to formalize in \ndx{Coq} an ICC-based complexity analysis technique,
the \emph{mwp-flow analysis}~\cite{jones2009}.\footnote{
    Where mwp stands for \emph{m}aximum, \emph{w}eak polynomial and
    \emph{p}olynomial, representing increasing growth rates of variables
    values.}
We chose this method because its internal mechanics has been recently
studied~\cite{aubert20222}, and by our assessment, it seems suitable for
formalization in \ndx{Coq}. As for \ndx{Coq}, it seems like the ideal target
language because of its existing libraries and preliminary work--some of which
are discussed in \autoref{subsec:coqpl-related}--, most notably related to
compilers~\cite{leroy2009}.

\subsubsection{Overview of \emph{mwp}-Flow Analysis}
\label{subsubsec:coqpl-overview-of-mwp-flow-analysis}

The \emph{mwp}-flow analysis certifies polynomial bounds on the size of the values manipulated by an imperative program.
While it does not ensure (or require) program termination, it provides a certificate guaranteeing that the program uses throughout its execution at most a polynomial amount of space, and as a consequence that if it terminates, it will do so in polynomial time in the size of its inputs.

The analysis computes, for each program variable, a vector tracking how it depends on other variables.
The vector values are determined by applying the nondeterminitic rules of the sound \emph{mwp}-calculus to the commands of the program.
Those vectors are collected in a matrix\index{mwp-matrix}.
A program is assigned a matrix\index{mwp-matrix} only if all the values in it are bounded by a polynomial in the inputs sizes.
This technique is compositional, abstracts away \eg iteration bounds, and operates on a memory-less imperative language, reminiscent of the \texttt{Imp} language from Software Foundations~\cite{cpierce20221}\index{Software Foundations}.

\subsubsection{The \ndx{Coq} Formalization}
\label{subsubsec:coqpl-the-coq-formalization}

Our goal is to certify the analysis as presented in {the original paper}~\cite{jones2009}.
Note that this does not mean that the bound is certified, but that \emph{the mechanism to compute those bounds} is certified.
Of course, this implies the correctness of the bounds as a by-product but constitutes a major difference \wrt the results discussed in \autoref{subsec:coqpl-related}.
Preliminary explorations have led us to establish the following milestones.

\begin{description}
    \item[The mathematical foundations]
    Our first goal is to define the mathematical structure required to carry out the rest of the construction.
    This requires defining vectors, matrices and their operations, semi-rings, and honest polynomials\index{honest polynomial}\footnote{%
        Which are \textcquote[p.~5]{jones2009}{polynomial build up from constants in \(\mathbb{N}\) and variables by applying the operations \(+\) (addition) and \(\times\) (multiplication).}} that are needed to represent the \emph{mwp}-bounds\index{mwp-bound}.
    The Mathematical Components library~\cite{mahboubi2022,mathcomp}\index{Mathematical Components} will lay the foundations for the linear algebra representations, but likely requires extensions to accommodate our specific analysis.

    \item[Implementing the language]
    The analyzed language is a simple imperative language that manipulates natural numbers, held in a fixed number of program variables.
    Its syntax includes variables, expressions (operations \(+\) and \(\times\)), Boolean expressions, and commands
    (\eg  assignment, loop and decision statements, command sequences, and skip), with their usual semantics.
    We expect implementing it and its small-steps semantics\index{small-steps semantics} in Coq\index{Coq} to be relatively simple, following the examples from Software Foundations~\cite{cpierce20221,cpierce20222}\index{Software Foundations}.

    \item[Implementing the typing system]
    Even if it can be computationally expensive to run an automatic inference~\cite{aubert2023b}, the typing system \emph{in itself} is relatively simple.
    It contains only 10 rules, essentially one for each type of command, and except for the initial assignment of vectors to variables, is fully deterministic.
    We conjecture that standard methods~\cite{chlipala2022, chlipala2010} to implement simple type systems will be enough, but will require some care to scale to the matrix-as-type paradigm of this analysis.

    \item[Certifying the analysis]
    This will be the most demanding part of our plan.
    The original paper contains all the required handwritten proofs, but the authors caution that
    \enquote{\textins{t}hese proofs are long, technical and occasionally highly nontrivial}~\cite[p.~2]{jones2009}.
    The main result of the paper is the soundness proof of the analysis~\cite[Theorem 5.3]{jones2009},
    \ie the proof of the existence of a matrix\index{mwp-matrix} typing the program implies the existence of an honest polynomial\index{honest polynomial} bounding the variables' growth rates.
    The main result follows from 15 pages of proofs presented in section 7 of the paper.
    This section revolves around proving the soundness properties of the calculus, and we expect the most substantial effort to be spent on formalizing these proofs.
    Some of them are quite intricate but with a satisfactory level of detail.
    The cases concerning soundness of loops are the most difficult on paper, but their inductive nature \emph{should} (we hope!) be processed by Coq\index{Coq} rather easily.
\end{description}

We leave for future work the possibility of creating a formally verified, automatic static analyzer founded on the proof of correctness of this method: as we discussed in other works~\cite{aubert2023b,aubert20222}, care is required to implement a typing strategy that does not rapidly become intractable.

\subsection{Related Work}
\label{subsec:coqpl-related}

A few prior results exist that combine formalization of complexity and \ndx{Coq}.
They range from practical analyses to proofs in computational complexity theory.

For practical application, Coq has been used to verify stack bounds for assembly code~\cite{carbonneaux2014} and to obtain WCET loop-bound estimation~\cite{blazy2013}.
    {Carbonneaux et al.}~\cite{carbonneaux2017} presented an automatic static analyzer for imperative programs, and although the analyzer itself is not verified, it generates bounds with machine-checkable certificates, to guarantee that the computed bound holds.
For functional paradigm, McCarthy et al.~\cite{mccarthy2018} developed a Coq\index{Coq} library, with a monad that counts abstract steps, which enabled running time analysis of programs written using the monad.
An ICC-based characterization was introduced by Férée et al.~\cite{feree2018}, in the form of a Coq\index{Coq} library, that allows for readily proving that a function is computable in polynomial time.

Coq\index{Coq} has also been used to formalize some of the foundations of modern complexity theory.
    {Ciaffaglione}~\cite{ciaffaglione2016} proved the undecidability of the halting problem.
    {Guéneau et al.}~\cite{gueneau2018} formalize the \(\mathcal{O}\)\symbo{bigo} notation.
    {Forster et al.}~\cite{forster2020} implemented a multi-tape to single-tape compiler, and introduced the first formalized
    \ndx{Universal Turing Machine} verified \wrt time\index{time complexity} and \ndx{space complexity},
    for any model of computation, in any \ndx{proof assistant}.
More recently, Gäher and Kunze formalized the \ndx{Cook-Levin theorem} in \ndx{Coq}~\cite{gaher2021}.
Despite these advances, formalization of complexity is in early stages and basic complexity-theoretic results \eg time and space hierarchy theorems, remain unavailable.

Our proposed project differs from these earlier results primarily in its intent.
We plan to formalize the complexity analysis mechanism itself---not its computed result, as was done previously.
In their work with the Turing Machines, Forster et al.~\cite{forster2020} were explicit in emphasizing the challenge they experienced in formalizing complexity.
We hypothesize that our ICC-based approach, with \eg its built-in abstractions, will help reduce this challenge.
It is our hope that CoqPL will welcome our proposal for a certified complexity analysis in Coq\index{Coq}, and will be keen on indicating any library, tool or resource that could help.
